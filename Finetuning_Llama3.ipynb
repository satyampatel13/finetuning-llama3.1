{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e00f91a",
   "metadata": {},
   "source": [
    "# Fine tuning Llama-3.1-8B with Finance Alpaca Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e86d2",
   "metadata": {},
   "source": [
    "## Installing the required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e7e56c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0a0+29c30b1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0a0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision transformers datasets bitsandbytes peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ae781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b033c",
   "metadata": {},
   "source": [
    "## Configure torch with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6a1b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Switch to GPU (cuda)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae256c",
   "metadata": {},
   "source": [
    "## Model Loading from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd0e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:58<00:00, 14.53s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf76c7",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2fe9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and split it into training and test set\n",
    "\n",
    "dataset = load_dataset(\"poornima9348/finance-alpaca-1k-test\")\n",
    "\n",
    "train_test_split = dataset['test'].train_test_split(test_size=0.2, shuffle=True)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f409a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'text'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "}) dict_keys(['test'])\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at our dataset and how a single data point looks like\n",
    "print(dataset, dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns 'input' and 'text' (there are no values in those columns)\n",
    "train_dataset = train_dataset.remove_columns(['input', 'text'])\n",
    "test_dataset = test_dataset.remove_columns(['input', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb59543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 6625.26 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 9912.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset example: {'instruction': 'If I own x% of company A, and A buys company B, do I own x% of B?', 'output': \"No, thanks to the principle of corporate personhood.  The legal entity (company C) is the owner and parent of the private company (sub S).  You and C are separate legal entities, as are C and S. This principle helps to legally insulate the parties for purposes such as liability, torts, taxes, and so forth.  If company C is sued, you may be financially at stake (i.e. your investment in C is devalued or made worthless) but you are not personally being sued.  However, the litigant may attach you as an additional litigant if the facts of the suit merit it.  But without legal separateness of corporations, then potentially all owners and maybe a number of the employees would be sued any time somebody sued the business - which is messy for companies and messy for litigants.  It's also far cleaner for lenders to lend to  unified business entities rather than a variety of thousands of ever-shifting shareholders. Note that this is a separate analysis that assumes the companies are not treated as partnerships or disregarded entities (tax nothings) for tax purposes, in which case an owner may for some purposes be imputed to own the assets of C.  I've also ignored the consolidated tax return, which would allow C and S to file a type of corporate joint return that for some purposes treats them similarly to common entity. For the simplest variation of your question, the answer is no.  You do not own the assets of a corporation by virtue of owning a few of its shares. Edit:  In light of your edit to include FB and Whatsapp, and the wrinkle about corporate books.  If sub S is 100% owned by company C, then you do not have any inspection rights to S because you are not a shareholder.  You also do not have virtual corporation inspection rights through company C.  However, if a person has inspection rights to company C, and sub S appears on the books and financial records of C, then your C rights will do the job of seeing S information. However, Facebook is a public company, so they will make regular public filings and disclosures that should at least partly cover Whatsapp.  So I hedge and clear my throat by averring that my securities training is limited, but I believe that the SEC filings of a public company will as a practical matter (maybe a matter of law?) moot the inspection rights.  At the very least, I suspect you'd need a proper purpose (under DGCL, for example), to demand the inspection, and they will have already made extensive disclosures that I believe will be presumptively sufficient.  I defer to more experienced securities experts on that question, but I don't believe inspection rights are designed for public companies.\", 'text': \"If I own x% of company A, and A buys company B, do I own x% of B?No, thanks to the principle of corporate personhood.  The legal entity (company C) is the owner and parent of the private company (sub S).  You and C are separate legal entities, as are C and S. This principle helps to legally insulate the parties for purposes such as liability, torts, taxes, and so forth.  If company C is sued, you may be financially at stake (i.e. your investment in C is devalued or made worthless) but you are not personally being sued.  However, the litigant may attach you as an additional litigant if the facts of the suit merit it.  But without legal separateness of corporations, then potentially all owners and maybe a number of the employees would be sued any time somebody sued the business - which is messy for companies and messy for litigants.  It's also far cleaner for lenders to lend to  unified business entities rather than a variety of thousands of ever-shifting shareholders. Note that this is a separate analysis that assumes the companies are not treated as partnerships or disregarded entities (tax nothings) for tax purposes, in which case an owner may for some purposes be imputed to own the assets of C.  I've also ignored the consolidated tax return, which would allow C and S to file a type of corporate joint return that for some purposes treats them similarly to common entity. For the simplest variation of your question, the answer is no.  You do not own the assets of a corporation by virtue of owning a few of its shares. Edit:  In light of your edit to include FB and Whatsapp, and the wrinkle about corporate books.  If sub S is 100% owned by company C, then you do not have any inspection rights to S because you are not a shareholder.  You also do not have virtual corporation inspection rights through company C.  However, if a person has inspection rights to company C, and sub S appears on the books and financial records of C, then your C rights will do the job of seeing S information. However, Facebook is a public company, so they will make regular public filings and disclosures that should at least partly cover Whatsapp.  So I hedge and clear my throat by averring that my securities training is limited, but I believe that the SEC filings of a public company will as a practical matter (maybe a matter of law?) moot the inspection rights.  At the very least, I suspect you'd need a proper purpose (under DGCL, for example), to demand the inspection, and they will have already made extensive disclosures that I believe will be presumptively sufficient.  I defer to more experienced securities experts on that question, but I don't believe inspection rights are designed for public companies.\"}\n",
      "Test dataset example: {'instruction': 'Is house swapping possible?', 'output': \"Another possibility that you might consider is to find a renter for your current place and move to your destination. If you have a lease for your renter, your mortgage company can consider that as income for approving the purchase of a new house. I did something similar when I purchased my current home, but I was also able to get approved without selling or renting the old place. There's no reason that someone couldn't create a house swapping site for longer-term than a week. It may not initially have as much demand as a 1 week swap, but there are no such existing services that I am aware of.\", 'text': \"Is house swapping possible?Another possibility that you might consider is to find a renter for your current place and move to your destination. If you have a lease for your renter, your mortgage company can consider that as income for approving the purchase of a new house. I did something similar when I purchased my current home, but I was also able to get approved without selling or renting the old place. There's no reason that someone couldn't create a house swapping site for longer-term than a week. It may not initially have as much demand as a 1 week swap, but there are no such existing services that I am aware of.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 800/800 [00:00<00:00, 880.02 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 1744.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "def prompt_builder(row):\n",
    "    return {\"text\": row[\"instruction\"] + row[\"output\"]}\n",
    "\n",
    "train_dataset =train_dataset.map(prompt_builder)\n",
    "test_dataset =test_dataset.map(prompt_builder)\n",
    "\n",
    "print(\"Train dataset example:\", train_dataset[0])\n",
    "print(\"Test dataset example:\", test_dataset[0])\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert datasets to PyTorch tensors\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "train_dataset = train_dataset.remove_columns(['instruction', 'output'])\n",
    "test_dataset = test_dataset.remove_columns(['instruction', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598afe7",
   "metadata": {},
   "source": [
    "## Turn the model into LoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ea41b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "peft_model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4929021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=32, target_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, #the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters\n",
    "    lora_alpha=32, #LoRA scaling factor\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    #target_modules='all-linear' # The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
    ")\n",
    "\n",
    "lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df90ea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear8bitLt(\n",
       "                (base_layer): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model = get_peft_model(peft_model, lora_config)\n",
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f66900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.1695\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a698801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding,DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"Meta-Llama-3.1-8B-Instruct-finetuned\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_steps=1,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb4f44",
   "metadata": {},
   "source": [
    "## Let's start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedb131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:418: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 1:11:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.717400</td>\n",
       "      <td>2.631765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=2.643162889778614, metrics={'train_runtime': 4276.0884, 'train_samples_per_second': 0.187, 'train_steps_per_second': 0.187, 'total_flos': 8.0586892345344e+16, 'train_loss': 2.643162889778614, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82879235",
   "metadata": {},
   "source": [
    "## Generate the first response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7849b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does a brokerage firm work?A brokerage firm is a company that acts as an intermediary between investors and the stock market. It allows its customers to buy and sell securities, such as stocks, bonds, and mutual funds. In exchange for its services, the brokerage firm charges a commission or fee to the investor. Here's a step-by-step explanation of how a brokerage firm works: 1. The investor opens a brokerage account with the firm. 2. The investor deposits funds into the account. 3. The investor places\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Load the fine-tuned model with the adapter attached\n",
    "model_with_adapter = PeftModel.from_pretrained(model, \"Meta-Llama-3.1-8B-Instruct-finetuned/checkpoint-800\").to(\"cuda\")\n",
    "model_with_adapter.eval()\n",
    "inputs = tokenizer(\"How does a brokerage firm work?\", return_tensors=\"pt\")\n",
    "\n",
    "outputs = model_with_adapter.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=100)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3821ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
